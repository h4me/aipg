blocks {
  idx: 0
  parent_idx: -1
  vars {
    name: "fetch"
    type {
      type: FETCH_LIST
    }
    persistable: true
  }
  vars {
    name: "feed"
    type {
      type: FEED_MINIBATCH
    }
    persistable: true
  }
  vars {
    name: "conv2d_22.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
          dims: 128
          dims: 3
          dims: 3
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_21.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 128
          dims: 28
          dims: 28
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_2.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 64
          dims: 55
          dims: 55
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_22.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_52.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 2048
        }
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_19.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
          dims: 128
          dims: 3
          dims: 3
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_21.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_18.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
          dims: 512
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_26.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_30.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 1024
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_18.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 128
          dims: 28
          dims: 28
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_9.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 64
          dims: 55
          dims: 55
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_16.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
          dims: 128
          dims: 3
          dims: 3
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_15.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
          dims: 512
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_15.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 128
          dims: 28
          dims: 28
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_11.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
          dims: 256
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_22.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 128
          dims: 28
          dims: 28
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_10.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 55
          dims: 55
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_27.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 1024
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_1.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
          dims: 64
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_30.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_1.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 55
          dims: 55
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_22.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_0.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 64
          dims: 112
          dims: 112
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_9.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_21.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
          dims: 512
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_43.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 2048
          dims: 1024
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_12.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 128
          dims: 28
          dims: 28
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_43.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 2048
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_30.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
          dims: 256
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_8.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_17.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 512
          dims: 28
          dims: 28
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_8.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_7.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 55
          dims: 55
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_15.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_7.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_7.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_6.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: true
  }
  vars {
    name: "label"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: INT64
          dims: -1
          dims: 1
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_6.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_6.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 64
          dims: 55
          dims: 55
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_6.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_52.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 2048
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_8.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_52.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 2048
          dims: 7
          dims: 7
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_43.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 2048
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_52.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 2048
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_46.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 2048
          dims: 512
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_52.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 2048
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_52.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 2048
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_48.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 512
          dims: 7
          dims: 7
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_7.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_51.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_51.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_50.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_50.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_5.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
          dims: 256
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_5.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 64
          dims: 55
          dims: 55
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_50.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 512
          dims: 7
          dims: 7
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_41.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_26.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_5.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_5.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_8.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
          dims: 256
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_49.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 2048
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_46.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 2048
          dims: 7
          dims: 7
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_49.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 2048
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_49.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 2048
        }
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_9.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
          dims: 64
          dims: 3
          dims: 3
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_49.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 2048
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_29.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_48.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_48.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_48.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_13.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "fc_0.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 102
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_48.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_47.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_2.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_47.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 512
          dims: 7
          dims: 7
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_47.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_36.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: false
  }
  vars {
    name: "elementwise_add_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 55
          dims: 55
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_47.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_33.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_46.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 2048
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_52.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 2048
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_46.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 2048
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_46.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 2048
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_17.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_46.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 2048
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_42.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_20.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_46.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 2048
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_45.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_45.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_22.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_45.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_44.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_44.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_39.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_31.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_13.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: false
  }
  vars {
    name: "elementwise_add_4"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 512
          dims: 28
          dims: 28
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_0.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_29.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_0.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: true
  }
  vars {
    name: "accuracy_1.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: INT64
          dims: 1
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_24.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_47.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_27.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_24.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_26.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_15.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_10.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_11.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_0.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_19.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_11.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 512
          dims: 28
          dims: 28
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_28.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_9.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 64
          dims: 55
          dims: 55
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_26.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_17.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_36.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 1024
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_40.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
          dims: 1024
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_29.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
          dims: 256
          dims: 3
          dims: 3
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_6.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_12.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 128
          dims: 28
          dims: 28
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_40.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_19.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_8.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 64
          dims: 55
          dims: 55
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_16.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_13.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 128
          dims: 28
          dims: 28
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_2.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_10.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 55
          dims: 55
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_29.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_12.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_34.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
          dims: 1024
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_26.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_0.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 64
          dims: 112
          dims: 112
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_42.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_37.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_27.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 1024
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_20.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_32.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_21.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_11.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_16.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 128
          dims: 28
          dims: 28
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "elementwise_add_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 55
          dims: 55
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_44.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_4.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_23.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_44.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 512
          dims: 7
          dims: 7
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_21.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_49.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 2048
          dims: 7
          dims: 7
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_15.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 128
          dims: 28
          dims: 28
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_24.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_21.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_21.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 128
          dims: 28
          dims: 28
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_20.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_7.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_8.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: false
  }
  vars {
    name: "mean_0.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_20.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_30.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_38.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_39.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_50.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_10.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_33.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_42.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_27.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_33.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_51.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 512
          dims: 7
          dims: 7
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_22.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_23.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_23.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_47.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_31.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_0.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_29.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_23.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_19.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_50.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
          dims: 2048
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_27.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_28.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_34.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_28.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_35.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_35.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
          dims: 256
          dims: 3
          dims: 3
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_1.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_13.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_47.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 512
          dims: 7
          dims: 7
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_39.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 1024
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "elementwise_add_10"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 1024
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_18.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_14.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "cross_entropy_0.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 1
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_25.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "accuracy_1.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_37.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_32.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_38.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
          dims: 256
          dims: 3
          dims: 3
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_3.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_39.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
          dims: 256
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_45.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 512
          dims: 7
          dims: 7
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "elementwise_add_13"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 2048
          dims: 7
          dims: 7
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_45.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_44.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 512
          dims: 7
          dims: 7
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_12.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_26.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_13.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
          dims: 128
          dims: 3
          dims: 3
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_48.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 512
          dims: 7
          dims: 7
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_30.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_49.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 2048
          dims: 512
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_3.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_33.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_44.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
          dims: 1024
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_50.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 512
          dims: 7
          dims: 7
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_2.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_20.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 512
          dims: 28
          dims: 28
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_21.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: false
  }
  vars {
    name: "fc_0.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 102
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_13.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 128
          dims: 28
          dims: 28
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_28.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
          dims: 1024
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_39.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_12.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_30.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_12.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_34.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_26.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "pool2d_0.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 64
          dims: 55
          dims: 55
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_42.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 1024
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "fc_0.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 2048
          dims: 102
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_2.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_21.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_34.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_25.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_33.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 1024
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_37.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
          dims: 1024
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_3.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_51.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_24.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 1024
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_18.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 128
          dims: 28
          dims: 28
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "elementwise_add_8"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 1024
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_42.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 1024
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_3.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_0.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_20.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_47.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
          dims: 2048
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "pool2d_1.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 2048
          dims: 1
          dims: 1
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_25.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "elementwise_add_9"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 1024
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "top_k_0.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: INT64
          dims: -1
          dims: 1
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "top_k_1.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 5
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "elementwise_add_6"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 512
          dims: 28
          dims: 28
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "elementwise_add_3"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 512
          dims: 28
          dims: 28
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_6.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
          dims: 64
          dims: 3
          dims: 3
        }
      }
    }
    persistable: true
  }
  vars {
    name: "top_k_0.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 1
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_29.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_32.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_12.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
          dims: 256
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_32.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "elementwise_add_5"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 512
          dims: 28
          dims: 28
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "elementwise_add_14"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 2048
          dims: 7
          dims: 7
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_17.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_43.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 2048
          dims: 7
          dims: 7
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_31.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
          dims: 1024
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_51.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
          dims: 512
          dims: 3
          dims: 3
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_18.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "elementwise_add_7"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 1024
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_36.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_15.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_50.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "data"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 3
          dims: 224
          dims: 224
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_52.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 2048
          dims: 7
          dims: 7
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_51.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 512
          dims: 7
          dims: 7
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_32.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_13.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_10.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_31.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_44.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_18.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_52.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 2048
          dims: 512
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "elementwise_add_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 55
          dims: 55
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_36.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
          dims: 256
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_3.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 64
          dims: 55
          dims: 55
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_28.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_41.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
          dims: 256
          dims: 3
          dims: 3
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_27.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
          dims: 256
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_26.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
          dims: 256
          dims: 3
          dims: 3
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_7.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_42.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
          dims: 256
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_32.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
          dims: 256
          dims: 3
          dims: 3
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_16.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_25.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
          dims: 512
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_23.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
          dims: 128
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_24.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 1024
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_10.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_24.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_45.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
          dims: 512
          dims: 3
          dims: 3
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_33.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
          dims: 256
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_31.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_26.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_34.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_34.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_5.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 64
          dims: 55
          dims: 55
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_31.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_25.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_28.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "accuracy_0.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: INT64
          dims: 1
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_5.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_27.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_11.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_35.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_3.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_14.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_6.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_25.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "accuracy_0.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_32.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_20.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
          dims: 128
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_17.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_25.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_12.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_23.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_19.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_46.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 2048
          dims: 7
          dims: 7
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_7.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
          dims: 64
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_28.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_18.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "accuracy_1.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: INT64
          dims: 1
        }
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_14.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 512
          dims: 28
          dims: 28
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_40.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_16.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_10.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_5.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_18.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_50.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_36.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_29.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_31.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_23.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: false
  }
  vars {
    name: "elementwise_add_12"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 1024
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_3.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_29.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_1.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_24.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_27.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: false
  }
  vars {
    name: "elementwise_add_15"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 2048
          dims: 7
          dims: 7
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_37.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_1.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_37.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_32.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_1.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 55
          dims: 55
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_11.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_31.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_1.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_25.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_13.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_19.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 128
          dims: 28
          dims: 28
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_16.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 128
          dims: 28
          dims: 28
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_41.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_22.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_2.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 64
          dims: 55
          dims: 55
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_20.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_3.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 64
          dims: 55
          dims: 55
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_23.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 512
          dims: 28
          dims: 28
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_9.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_45.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 512
          dims: 7
          dims: 7
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_46.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 2048
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_14.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_19.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_6.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_1.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_14.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_14.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 512
          dims: 28
          dims: 28
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_16.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_28.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_42.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_49.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 2048
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_1.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_10.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_34.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_15.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_24.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_27.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_41.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_38.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_17.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
          dims: 128
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_4.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 55
          dims: 55
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_25.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_18.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: false
  }
  vars {
    name: "accuracy_0.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: INT64
          dims: 1
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_39.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_15.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_4.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_44.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_45.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_12.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_48.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_5.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_16.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_2.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_31.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_8.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_17.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_41.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_32.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_9.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_48.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
          dims: 512
          dims: 3
          dims: 3
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_4.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
          dims: 64
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_19.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_2.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_51.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_33.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_37.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_33.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 1024
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_33.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_51.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_34.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_34.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_35.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_9.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_3.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
          dims: 64
          dims: 3
          dims: 3
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_35.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_40.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_35.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_49.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 2048
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_13.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_35.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_35.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_39.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 1024
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_11.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_15.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "elementwise_add_11"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 1024
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_29.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_35.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_48.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_36.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 1024
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_7.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_30.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_0.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
          dims: 3
          dims: 7
          dims: 7
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_36.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_2.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
          dims: 64
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_17.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_36.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_36.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_38.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_37.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_37.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_50.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_5.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_10.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
          dims: 64
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_14.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
          dims: 128
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_20.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 512
          dims: 28
          dims: 28
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_30.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_37.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_0.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_38.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_8.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_39.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: false
  }
  vars {
    name: "top_k_1.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: INT64
          dims: -1
          dims: 5
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_38.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_43.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 2048
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_38.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_22.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 128
          dims: 28
          dims: 28
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_38.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_39.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_28.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_45.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_40.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_19.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 128
          dims: 28
          dims: 28
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_4.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_4.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_22.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_9.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_9.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 64
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_51.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_14.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_4.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 55
          dims: 55
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "conv2d_6.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 64
          dims: 55
          dims: 55
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_4.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_11.w_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_4.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_40.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_24.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
          dims: 512
          dims: 1
          dims: 1
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_23.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 512
          dims: 28
          dims: 28
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_40.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_40.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_43.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 2048
          dims: 7
          dims: 7
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_40.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "conv2d_11.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 512
          dims: 28
          dims: 28
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_14.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_41.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_47.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_41.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_41.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_38.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 256
          dims: 14
          dims: 14
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_41.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 256
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_42.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_16.tmp_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 128
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_42.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 1024
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_43.b_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 2048
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_44.w_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 512
        }
      }
    }
    persistable: true
  }
  vars {
    name: "batch_norm_43.tmp_1"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 2048
        }
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_8.tmp_2"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: -1
          dims: 64
          dims: 55
          dims: 55
        }
        lod_level: 0
      }
    }
    persistable: false
  }
  vars {
    name: "batch_norm_43.w_0"
    type {
      type: LOD_TENSOR
      lod_tensor {
        tensor {
          data_type: FP32
          dims: 2048
        }
      }
    }
    persistable: true
  }

  ops {
    inputs {
      parameter: "X"
      arguments: "feed"
    }
    outputs {
      parameter: "Out"
      arguments: "label"
    }
    type: "feed"
    attrs {
      name: "col"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1367, in _prepend_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/io.py\", line 837, in prepend_feed_ops\n    attrs={\'col\': i})\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/io.py\", line 972, in save_inference_model\n    prepend_feed_ops(main_program, feeded_var_names)\n"
      strings: "  File \"train_resnet.py\", line 408, in train\n    [\"data\", \"label\"], [avg_cost, acc_top1, acc_top5], exe)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "feed"
    }
    outputs {
      parameter: "Out"
      arguments: "data"
    }
    type: "feed"
    attrs {
      name: "col"
      type: INT
      i: 0
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1367, in _prepend_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/io.py\", line 837, in prepend_feed_ops\n    attrs={\'col\': i})\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/io.py\", line 972, in save_inference_model\n    prepend_feed_ops(main_program, feeded_var_names)\n"
      strings: "  File \"train_resnet.py\", line 408, in train\n    [\"data\", \"label\"], [avg_cost, acc_top1, acc_top5], exe)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_0.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "data"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_0.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 185, in resnet_imagenet\n    conv1 = conv_bn_layer(input, ch_out=64, filter_size=7, stride=2, padding=3)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 2
      ints: 2
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 3
      ints: 3
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_0.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_0.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_0.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_0.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_0.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_0.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_0.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_0.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_0.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_0.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 185, in resnet_imagenet\n    conv1 = conv_bn_layer(input, ch_out=64, filter_size=7, stride=2, padding=3)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_0.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_0.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 185, in resnet_imagenet\n    conv1 = conv_bn_layer(input, ch_out=64, filter_size=7, stride=2, padding=3)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_0.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "pool2d_0.tmp_0"
    }
    type: "pool2d"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "pooling_type"
      type: STRING
      s: "avg"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2486, in pool2d\n    \"exclusive\": exclusive,\n"
      strings: "  File \"train_resnet.py\", line 187, in resnet_imagenet\n    pool_stride=2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "ceil_mode"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "adaptive"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "ksize"
      type: INTS
      ints: 3
      ints: 3
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 2
      ints: 2
    }
    attrs {
      name: "exclusive"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "global_pooling"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_1.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "pool2d_0.tmp_0"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_1.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 145, in shortcut\n    return conv_bn_layer(input, ch_out, 1, stride, 0, None)\n"
      strings: "  File \"train_resnet.py\", line 158, in bottleneck\n    short = shortcut(input, ch_out * 4, stride)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_1.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_1.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_1.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_1.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_1.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_1.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_1.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_1.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_1.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_1.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 145, in shortcut\n    return conv_bn_layer(input, ch_out, 1, stride, 0, None)\n"
      strings: "  File \"train_resnet.py\", line 158, in bottleneck\n    short = shortcut(input, ch_out * 4, stride)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_2.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "pool2d_0.tmp_0"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_2.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_2.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_2.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_2.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_2.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_2.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_2.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_2.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_2.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_2.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_2.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_2.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_2.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_3.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_2.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_3.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_3.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_3.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_3.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_3.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_3.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_3.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_3.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_3.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_3.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_3.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_3.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_3.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_4.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_3.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_4.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_4.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_4.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_4.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_4.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_4.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_4.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_4.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_4.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_4.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_4.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_1.tmp_2"
    }
    inputs {
      parameter: "Y"
      arguments: "batch_norm_4.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_0"
    }
    type: "elementwise_add"
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8556, in _elementwise_op\n    \'use_mkldnn\': use_mkldnn})\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "y_data_format"
      type: STRING
      s: ""
    }
    attrs {
      name: "axis"
      type: INT
      i: -1
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "x_data_format"
      type: STRING
      s: ""
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "elementwise_add_0"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_0"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8557, in _elementwise_op\n    return helper.append_activation(out)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_5.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "elementwise_add_0"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_5.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_5.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_5.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_5.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_5.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_5.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_5.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_5.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_5.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_5.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_5.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_5.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_5.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_6.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_5.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_6.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_6.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_6.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_6.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_6.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_6.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_6.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_6.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_6.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_6.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_6.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_6.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_6.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_7.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_6.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "batch_norm_1.tmp_2"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_7.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_7.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_7.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_7.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "batch_norm_1.tmp_2"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_7.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_7.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_7.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_7.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_7.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "elementwise_add_0"
    }
    inputs {
      parameter: "Y"
      arguments: "batch_norm_7.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_1"
    }
    type: "elementwise_add"
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8556, in _elementwise_op\n    \'use_mkldnn\': use_mkldnn})\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "y_data_format"
      type: STRING
      s: ""
    }
    attrs {
      name: "axis"
      type: INT
      i: -1
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "x_data_format"
      type: STRING
      s: ""
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "elementwise_add_1"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_1"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8557, in _elementwise_op\n    return helper.append_activation(out)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_8.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "elementwise_add_1"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_8.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_8.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_8.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_8.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_8.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_8.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_8.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_8.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_8.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_8.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_8.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_8.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_8.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_9.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_8.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_9.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_9.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_9.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_9.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_9.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_9.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_9.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_9.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_9.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_9.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_9.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_9.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_9.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_10.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_9.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_10.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_10.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_10.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_10.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_10.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_10.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_10.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_10.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_10.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_10.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_10.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "elementwise_add_1"
    }
    inputs {
      parameter: "Y"
      arguments: "batch_norm_10.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_2"
    }
    type: "elementwise_add"
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8556, in _elementwise_op\n    \'use_mkldnn\': use_mkldnn})\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "y_data_format"
      type: STRING
      s: ""
    }
    attrs {
      name: "axis"
      type: INT
      i: -1
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "x_data_format"
      type: STRING
      s: ""
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "elementwise_add_2"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8557, in _elementwise_op\n    return helper.append_activation(out)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 188, in resnet_imagenet\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_11.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "elementwise_add_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_11.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 145, in shortcut\n    return conv_bn_layer(input, ch_out, 1, stride, 0, None)\n"
      strings: "  File \"train_resnet.py\", line 158, in bottleneck\n    short = shortcut(input, ch_out * 4, stride)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 2
      ints: 2
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_11.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_11.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_11.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_11.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_11.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_11.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_11.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_11.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_11.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_11.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 145, in shortcut\n    return conv_bn_layer(input, ch_out, 1, stride, 0, None)\n"
      strings: "  File \"train_resnet.py\", line 158, in bottleneck\n    short = shortcut(input, ch_out * 4, stride)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_12.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "elementwise_add_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_12.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 2
      ints: 2
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_12.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_12.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_12.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_12.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_12.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_12.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_12.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_12.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_12.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_12.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_12.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_12.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_13.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_12.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_13.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_13.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_13.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_13.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_13.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_13.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_13.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_13.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_13.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_13.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_13.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_13.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_13.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_14.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_13.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_14.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_14.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_14.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_14.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_14.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_14.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_14.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_14.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_14.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_14.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_14.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_11.tmp_2"
    }
    inputs {
      parameter: "Y"
      arguments: "batch_norm_14.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_3"
    }
    type: "elementwise_add"
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8556, in _elementwise_op\n    \'use_mkldnn\': use_mkldnn})\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "y_data_format"
      type: STRING
      s: ""
    }
    attrs {
      name: "axis"
      type: INT
      i: -1
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "x_data_format"
      type: STRING
      s: ""
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "elementwise_add_3"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_3"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8557, in _elementwise_op\n    return helper.append_activation(out)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_15.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "elementwise_add_3"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_15.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_15.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_15.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_15.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_15.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_15.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_15.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_15.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_15.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_15.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_15.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_15.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_15.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_16.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_15.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_16.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_16.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_16.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_16.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_16.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_16.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_16.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_16.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_16.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_16.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_16.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_16.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_16.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_17.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_16.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "batch_norm_11.tmp_2"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_17.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_17.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_17.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_17.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "batch_norm_11.tmp_2"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_17.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_17.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_17.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_17.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_17.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "elementwise_add_3"
    }
    inputs {
      parameter: "Y"
      arguments: "batch_norm_17.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_4"
    }
    type: "elementwise_add"
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8556, in _elementwise_op\n    \'use_mkldnn\': use_mkldnn})\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "y_data_format"
      type: STRING
      s: ""
    }
    attrs {
      name: "axis"
      type: INT
      i: -1
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "x_data_format"
      type: STRING
      s: ""
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "elementwise_add_4"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_4"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8557, in _elementwise_op\n    return helper.append_activation(out)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_18.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "elementwise_add_4"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_18.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_18.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_18.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_18.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_18.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_18.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_18.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_18.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_18.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_18.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_18.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_18.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_18.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_19.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_18.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_19.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_19.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_19.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_19.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_19.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_19.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_19.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_19.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_19.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_19.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_19.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_19.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_19.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_20.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_19.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_20.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_20.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_20.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_20.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_20.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_20.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_20.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_20.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_20.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_20.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_20.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "elementwise_add_4"
    }
    inputs {
      parameter: "Y"
      arguments: "batch_norm_20.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_5"
    }
    type: "elementwise_add"
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8556, in _elementwise_op\n    \'use_mkldnn\': use_mkldnn})\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "y_data_format"
      type: STRING
      s: ""
    }
    attrs {
      name: "axis"
      type: INT
      i: -1
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "x_data_format"
      type: STRING
      s: ""
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "elementwise_add_5"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_5"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8557, in _elementwise_op\n    return helper.append_activation(out)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_21.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "elementwise_add_5"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_21.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_21.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_21.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_21.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_21.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_21.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_21.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_21.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_21.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_21.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_21.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_21.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_21.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_22.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_21.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_22.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_22.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_22.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_22.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_22.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_22.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_22.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_22.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_22.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_22.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_22.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_22.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_22.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_23.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_22.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_23.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_23.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_23.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_23.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_23.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_23.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_23.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_23.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_23.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_23.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_23.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "elementwise_add_5"
    }
    inputs {
      parameter: "Y"
      arguments: "batch_norm_23.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_6"
    }
    type: "elementwise_add"
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8556, in _elementwise_op\n    \'use_mkldnn\': use_mkldnn})\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "y_data_format"
      type: STRING
      s: ""
    }
    attrs {
      name: "axis"
      type: INT
      i: -1
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "x_data_format"
      type: STRING
      s: ""
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "elementwise_add_6"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_6"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8557, in _elementwise_op\n    return helper.append_activation(out)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 189, in resnet_imagenet\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_24.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "elementwise_add_6"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_24.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 145, in shortcut\n    return conv_bn_layer(input, ch_out, 1, stride, 0, None)\n"
      strings: "  File \"train_resnet.py\", line 158, in bottleneck\n    short = shortcut(input, ch_out * 4, stride)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 2
      ints: 2
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_24.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_24.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_24.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_24.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_24.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_24.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_24.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_24.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_24.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_24.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 145, in shortcut\n    return conv_bn_layer(input, ch_out, 1, stride, 0, None)\n"
      strings: "  File \"train_resnet.py\", line 158, in bottleneck\n    short = shortcut(input, ch_out * 4, stride)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_25.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "elementwise_add_6"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_25.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 2
      ints: 2
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_25.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_25.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_25.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_25.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_25.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_25.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_25.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_25.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_25.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_25.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_25.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_25.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_26.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_25.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_26.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_26.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_26.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_26.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_26.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_26.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_26.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_26.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_26.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_26.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_26.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_26.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_26.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_27.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_26.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_27.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_27.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_27.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_27.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_27.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_27.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_27.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_27.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_27.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_27.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_27.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_24.tmp_2"
    }
    inputs {
      parameter: "Y"
      arguments: "batch_norm_27.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_7"
    }
    type: "elementwise_add"
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8556, in _elementwise_op\n    \'use_mkldnn\': use_mkldnn})\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "y_data_format"
      type: STRING
      s: ""
    }
    attrs {
      name: "axis"
      type: INT
      i: -1
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "x_data_format"
      type: STRING
      s: ""
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "elementwise_add_7"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_7"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8557, in _elementwise_op\n    return helper.append_activation(out)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_28.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "elementwise_add_7"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_28.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_28.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_28.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_28.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_28.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_28.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_28.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_28.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_28.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_28.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_28.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_28.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_28.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_29.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_28.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_29.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_29.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_29.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_29.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_29.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_29.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_29.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_29.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_29.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_29.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_29.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_29.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_29.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_30.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_29.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "batch_norm_24.tmp_2"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_30.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_30.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_30.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_30.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "batch_norm_24.tmp_2"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_30.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_30.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_30.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_30.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_30.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "elementwise_add_7"
    }
    inputs {
      parameter: "Y"
      arguments: "batch_norm_30.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_8"
    }
    type: "elementwise_add"
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8556, in _elementwise_op\n    \'use_mkldnn\': use_mkldnn})\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "y_data_format"
      type: STRING
      s: ""
    }
    attrs {
      name: "axis"
      type: INT
      i: -1
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "x_data_format"
      type: STRING
      s: ""
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "elementwise_add_8"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_8"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8557, in _elementwise_op\n    return helper.append_activation(out)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_31.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "elementwise_add_8"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_31.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_31.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_31.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_31.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_31.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_31.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_31.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_31.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_31.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_31.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_31.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_31.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_31.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_32.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_31.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_32.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_32.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_32.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_32.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_32.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_32.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_32.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_32.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_32.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_32.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_32.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_32.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_32.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_33.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_32.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_33.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_33.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_33.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_33.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_33.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_33.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_33.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_33.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_33.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_33.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_33.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "elementwise_add_8"
    }
    inputs {
      parameter: "Y"
      arguments: "batch_norm_33.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_9"
    }
    type: "elementwise_add"
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8556, in _elementwise_op\n    \'use_mkldnn\': use_mkldnn})\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "y_data_format"
      type: STRING
      s: ""
    }
    attrs {
      name: "axis"
      type: INT
      i: -1
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "x_data_format"
      type: STRING
      s: ""
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "elementwise_add_9"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_9"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8557, in _elementwise_op\n    return helper.append_activation(out)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_34.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "elementwise_add_9"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_34.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_34.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_34.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_34.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_34.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_34.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_34.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_34.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_34.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_34.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_34.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_34.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_34.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_35.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_34.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_35.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_35.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_35.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_35.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_35.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_35.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_35.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_35.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_35.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_35.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_35.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_35.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_35.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_36.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_35.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_36.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_36.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_36.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_36.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_36.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_36.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_36.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_36.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_36.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_36.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_36.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "elementwise_add_9"
    }
    inputs {
      parameter: "Y"
      arguments: "batch_norm_36.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_10"
    }
    type: "elementwise_add"
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8556, in _elementwise_op\n    \'use_mkldnn\': use_mkldnn})\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "y_data_format"
      type: STRING
      s: ""
    }
    attrs {
      name: "axis"
      type: INT
      i: -1
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "x_data_format"
      type: STRING
      s: ""
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "elementwise_add_10"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_10"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8557, in _elementwise_op\n    return helper.append_activation(out)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_37.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "elementwise_add_10"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_37.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_37.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_37.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_37.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_37.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_37.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_37.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_37.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_37.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_37.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_37.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_37.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_37.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_38.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_37.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_38.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_38.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_38.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_38.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_38.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_38.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_38.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_38.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_38.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_38.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_38.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_38.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_38.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_39.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_38.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_39.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_39.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_39.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_39.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_39.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_39.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_39.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_39.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_39.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_39.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_39.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "elementwise_add_10"
    }
    inputs {
      parameter: "Y"
      arguments: "batch_norm_39.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_11"
    }
    type: "elementwise_add"
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8556, in _elementwise_op\n    \'use_mkldnn\': use_mkldnn})\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "y_data_format"
      type: STRING
      s: ""
    }
    attrs {
      name: "axis"
      type: INT
      i: -1
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "x_data_format"
      type: STRING
      s: ""
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "elementwise_add_11"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_11"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8557, in _elementwise_op\n    return helper.append_activation(out)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_40.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "elementwise_add_11"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_40.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_40.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_40.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_40.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_40.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_40.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_40.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_40.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_40.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_40.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_40.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_40.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_40.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_41.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_40.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_41.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_41.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_41.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_41.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_41.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_41.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_41.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_41.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_41.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_41.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_41.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_41.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_41.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_42.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_41.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_42.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_42.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_42.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_42.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_42.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_42.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_42.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_42.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_42.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_42.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_42.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "elementwise_add_11"
    }
    inputs {
      parameter: "Y"
      arguments: "batch_norm_42.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_12"
    }
    type: "elementwise_add"
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8556, in _elementwise_op\n    \'use_mkldnn\': use_mkldnn})\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "y_data_format"
      type: STRING
      s: ""
    }
    attrs {
      name: "axis"
      type: INT
      i: -1
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "x_data_format"
      type: STRING
      s: ""
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "elementwise_add_12"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_12"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8557, in _elementwise_op\n    return helper.append_activation(out)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 190, in resnet_imagenet\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_43.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "elementwise_add_12"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_43.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 145, in shortcut\n    return conv_bn_layer(input, ch_out, 1, stride, 0, None)\n"
      strings: "  File \"train_resnet.py\", line 158, in bottleneck\n    short = shortcut(input, ch_out * 4, stride)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 2
      ints: 2
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_43.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_43.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_43.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_43.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_43.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_43.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_43.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_43.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_43.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_43.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 145, in shortcut\n    return conv_bn_layer(input, ch_out, 1, stride, 0, None)\n"
      strings: "  File \"train_resnet.py\", line 158, in bottleneck\n    short = shortcut(input, ch_out * 4, stride)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_44.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "elementwise_add_12"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_44.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 2
      ints: 2
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_44.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_44.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_44.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_44.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_44.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_44.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_44.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_44.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_44.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_44.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_44.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_44.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_45.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_44.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_45.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_45.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_45.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_45.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_45.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_45.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_45.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_45.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_45.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_45.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_45.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_45.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_45.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_46.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_45.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_46.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_46.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_46.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_46.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_46.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_46.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_46.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_46.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_46.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_46.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_46.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_43.tmp_2"
    }
    inputs {
      parameter: "Y"
      arguments: "batch_norm_46.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_13"
    }
    type: "elementwise_add"
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8556, in _elementwise_op\n    \'use_mkldnn\': use_mkldnn})\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "y_data_format"
      type: STRING
      s: ""
    }
    attrs {
      name: "axis"
      type: INT
      i: -1
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "x_data_format"
      type: STRING
      s: ""
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "elementwise_add_13"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_13"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8557, in _elementwise_op\n    return helper.append_activation(out)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 166, in layer_warp\n    res_out = block_func(input, ch_out, stride)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_47.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "elementwise_add_13"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_47.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_47.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_47.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_47.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_47.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_47.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_47.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_47.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_47.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_47.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_47.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_47.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_47.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_48.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_47.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_48.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_48.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_48.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_48.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_48.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_48.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_48.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_48.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_48.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_48.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_48.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_48.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_48.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_49.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_48.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "batch_norm_43.tmp_2"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_49.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_49.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_49.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_49.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "batch_norm_43.tmp_2"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_49.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_49.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_49.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_49.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_49.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "elementwise_add_13"
    }
    inputs {
      parameter: "Y"
      arguments: "batch_norm_49.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_14"
    }
    type: "elementwise_add"
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8556, in _elementwise_op\n    \'use_mkldnn\': use_mkldnn})\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "y_data_format"
      type: STRING
      s: ""
    }
    attrs {
      name: "axis"
      type: INT
      i: -1
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "x_data_format"
      type: STRING
      s: ""
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "elementwise_add_14"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_14"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8557, in _elementwise_op\n    return helper.append_activation(out)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_50.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "elementwise_add_14"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_50.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_50.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_50.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_50.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_50.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_50.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_50.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_50.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_50.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_50.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_50.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_50.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_50.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 159, in bottleneck\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_51.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_50.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_51.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_51.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_51.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_51.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_51.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_51.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_51.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_51.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_51.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_51.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_51.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "batch_norm_51.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "batch_norm_51.tmp_2"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2937, in batch_norm\n    return helper.append_activation(batch_norm_out)\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 160, in bottleneck\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Bias"
    }
    inputs {
      parameter: "Filter"
      arguments: "conv2d_52.w_0"
    }
    inputs {
      parameter: "Input"
      arguments: "batch_norm_51.tmp_2"
    }
    inputs {
      parameter: "ResidualData"
    }
    outputs {
      parameter: "Output"
      arguments: "conv2d_52.tmp_0"
    }
    type: "conv2d"
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "fuse_relu_before_depthwise_conv"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1975, in conv2d\n    \'fuse_relu_before_depthwise_conv\': False\n"
      strings: "  File \"train_resnet.py\", line 138, in conv_bn_layer\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "dilations"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "Scale_out"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "force_fp32_output"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "Scale_weights"
      type: FLOATS
      floats: 1.0
    }
    attrs {
      name: "workspace_size_MB"
      type: INT
      i: 4096
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "exhaustive_search"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "Scale_in_eltwise"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "groups"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "Scale_in"
      type: FLOAT
      f: 1.0
    }
    attrs {
      name: "fuse_residual_connection"
      type: BOOLEAN
      b: false
    }
  }
  ops {
    inputs {
      parameter: "Bias"
      arguments: "batch_norm_52.b_0"
    }
    inputs {
      parameter: "Mean"
      arguments: "batch_norm_52.w_1"
    }
    inputs {
      parameter: "Scale"
      arguments: "batch_norm_52.w_0"
    }
    inputs {
      parameter: "Variance"
      arguments: "batch_norm_52.w_2"
    }
    inputs {
      parameter: "X"
      arguments: "conv2d_52.tmp_0"
    }
    outputs {
      parameter: "MeanOut"
      arguments: "batch_norm_52.w_1"
    }
    outputs {
      parameter: "SavedMean"
      arguments: "batch_norm_52.tmp_0"
    }
    outputs {
      parameter: "SavedVariance"
      arguments: "batch_norm_52.tmp_1"
    }
    outputs {
      parameter: "VarianceOut"
      arguments: "batch_norm_52.w_2"
    }
    outputs {
      parameter: "Y"
      arguments: "batch_norm_52.tmp_2"
    }
    type: "batch_norm"
    attrs {
      name: "data_layout"
      type: STRING
      s: "NCHW"
    }
    attrs {
      name: "epsilon"
      type: FLOAT
      f: 9.999999747378752e-06
    }
    attrs {
      name: "fuse_with_relu"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "use_global_stats"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "momentum"
      type: FLOAT
      f: 0.8999999761581421
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2934, in batch_norm\n    \"use_global_stats\": use_global_stats\n"
      strings: "  File \"train_resnet.py\", line 139, in conv_bn_layer\n    return fluid.layers.batch_norm(input=conv1, act=act)\n"
      strings: "  File \"train_resnet.py\", line 161, in bottleneck\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0, act=None)\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "elementwise_add_14"
    }
    inputs {
      parameter: "Y"
      arguments: "batch_norm_52.tmp_2"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_15"
    }
    type: "elementwise_add"
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8556, in _elementwise_op\n    \'use_mkldnn\': use_mkldnn})\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "y_data_format"
      type: STRING
      s: ""
    }
    attrs {
      name: "axis"
      type: INT
      i: -1
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "x_data_format"
      type: STRING
      s: ""
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "elementwise_add_15"
    }
    outputs {
      parameter: "Out"
      arguments: "elementwise_add_15"
    }
    type: "relu"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8557, in _elementwise_op\n    return helper.append_activation(out)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8597, in elementwise_add\n    return _elementwise_op(LayerHelper(\'elementwise_add\', **locals()))\n"
      strings: "  File \"train_resnet.py\", line 162, in bottleneck\n    return fluid.layers.elementwise_add(x=short, y=conv3, act=\'relu\')\n"
      strings: "  File \"train_resnet.py\", line 168, in layer_warp\n    res_out = block_func(res_out, ch_out, 1)\n"
      strings: "  File \"train_resnet.py\", line 191, in resnet_imagenet\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "elementwise_add_15"
    }
    outputs {
      parameter: "Out"
      arguments: "pool2d_1.tmp_0"
    }
    type: "pool2d"
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "pooling_type"
      type: STRING
      s: "avg"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 2486, in pool2d\n    \"exclusive\": exclusive,\n"
      strings: "  File \"train_resnet.py\", line 197, in resnet_imagenet\n    global_pooling=True)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "ceil_mode"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "adaptive"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
    attrs {
      name: "ksize"
      type: INTS
      ints: 7
      ints: 7
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "paddings"
      type: INTS
      ints: 0
      ints: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "strides"
      type: INTS
      ints: 1
      ints: 1
    }
    attrs {
      name: "exclusive"
      type: BOOLEAN
      b: true
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "global_pooling"
      type: BOOLEAN
      b: true
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "pool2d_1.tmp_0"
    }
    inputs {
      parameter: "Y"
      arguments: "fc_0.w_0"
    }
    outputs {
      parameter: "Out"
      arguments: "fc_0.tmp_0"
    }
    type: "mul"
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "y_num_col_dims"
      type: INT
      i: 1
    }
    attrs {
      name: "x_num_col_dims"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 283, in fc\n    \"y_num_col_dims\": 1})\n"
      strings: "  File \"train_resnet.py\", line 199, in resnet_imagenet\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "fc_0.tmp_0"
    }
    outputs {
      parameter: "Out"
      arguments: "fc_0.tmp_1"
    }
    type: "softmax"
    attrs {
      name: "use_cudnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 444, in append_activation\n    attrs=act)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 298, in fc\n    return helper.append_activation(pre_activation)\n"
      strings: "  File \"train_resnet.py\", line 199, in resnet_imagenet\n    bias_attr=False)\n"
      strings: "  File \"train_resnet.py\", line 266, in train\n    predict = model(input, class_dim)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "is_test"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "use_mkldnn"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "data_format"
      type: STRING
      s: "AnyLayout"
    }
  }
  ops {
    inputs {
      parameter: "Label"
      arguments: "label"
    }
    inputs {
      parameter: "X"
      arguments: "fc_0.tmp_1"
    }
    outputs {
      parameter: "Y"
      arguments: "cross_entropy_0.tmp_0"
    }
    type: "cross_entropy"
    attrs {
      name: "soft_label"
      type: BOOLEAN
      b: false
    }
    attrs {
      name: "ignore_index"
      type: INT
      i: -100
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 1408, in cross_entropy\n    \"ignore_index\": ignore_index})\n"
      strings: "  File \"train_resnet.py\", line 267, in train\n    cost = fluid.layers.cross_entropy(input=predict, label=label)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "cross_entropy_0.tmp_0"
    }
    outputs {
      parameter: "Out"
      arguments: "mean_0.tmp_0"
    }
    type: "mean"
    attrs {
      name: "op_role"
      type: INT
      i: 256
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 8869, in mean\n    type=\"mean\", inputs={\"X\": x}, attrs={}, outputs={\"Out\": out})\n"
      strings: "  File \"train_resnet.py\", line 268, in train\n    avg_cost = fluid.layers.mean(x=cost)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "K"
    }
    inputs {
      parameter: "X"
      arguments: "fc_0.tmp_1"
    }
    outputs {
      parameter: "Indices"
      arguments: "top_k_0.tmp_1"
    }
    outputs {
      parameter: "Out"
      arguments: "top_k_0.tmp_0"
    }
    type: "top_k"
    attrs {
      name: "k"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 4738, in topk\n    attrs=attrs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/metric_op.py\", line 60, in accuracy\n    topk_out, topk_indices = nn.topk(input, k=k)\n"
      strings: "  File \"train_resnet.py\", line 269, in train\n    acc_top1 = fluid.layers.accuracy(input=predict, label=label, k=1)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Indices"
      arguments: "top_k_0.tmp_1"
    }
    inputs {
      parameter: "Label"
      arguments: "label"
    }
    inputs {
      parameter: "Out"
      arguments: "top_k_0.tmp_0"
    }
    outputs {
      parameter: "Accuracy"
      arguments: "accuracy_0.tmp_0"
    }
    outputs {
      parameter: "Correct"
      arguments: "accuracy_0.tmp_1"
    }
    outputs {
      parameter: "Total"
      arguments: "accuracy_0.tmp_2"
    }
    type: "accuracy"
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/metric_op.py\", line 76, in accuracy\n    \"Total\": [total],\n"
      strings: "  File \"train_resnet.py\", line 269, in train\n    acc_top1 = fluid.layers.accuracy(input=predict, label=label, k=1)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "K"
    }
    inputs {
      parameter: "X"
      arguments: "fc_0.tmp_1"
    }
    outputs {
      parameter: "Indices"
      arguments: "top_k_1.tmp_1"
    }
    outputs {
      parameter: "Out"
      arguments: "top_k_1.tmp_0"
    }
    type: "top_k"
    attrs {
      name: "k"
      type: INT
      i: 5
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/nn.py\", line 4738, in topk\n    attrs=attrs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/metric_op.py\", line 60, in accuracy\n    topk_out, topk_indices = nn.topk(input, k=k)\n"
      strings: "  File \"train_resnet.py\", line 270, in train\n    acc_top5 = fluid.layers.accuracy(input=predict, label=label, k=5)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "Indices"
      arguments: "top_k_1.tmp_1"
    }
    inputs {
      parameter: "Label"
      arguments: "label"
    }
    inputs {
      parameter: "Out"
      arguments: "top_k_1.tmp_0"
    }
    outputs {
      parameter: "Accuracy"
      arguments: "accuracy_1.tmp_0"
    }
    outputs {
      parameter: "Correct"
      arguments: "accuracy_1.tmp_1"
    }
    outputs {
      parameter: "Total"
      arguments: "accuracy_1.tmp_2"
    }
    type: "accuracy"
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layer_helper.py\", line 56, in append_op\n    return self.main_program.current_block().append_op(*args, **kwargs)\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/layers/metric_op.py\", line 76, in accuracy\n    \"Total\": [total],\n"
      strings: "  File \"train_resnet.py\", line 270, in train\n    acc_top5 = fluid.layers.accuracy(input=predict, label=label, k=5)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "mean_0.tmp_0"
    }
    outputs {
      parameter: "Out"
      arguments: "fetch"
    }
    type: "fetch"
    attrs {
      name: "col"
      type: INT
      i: 0
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/io.py\", line 854, in append_fetch_ops\n    attrs={\'col\': i})\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/io.py\", line 973, in save_inference_model\n    append_fetch_ops(main_program, fetch_var_names)\n"
      strings: "  File \"train_resnet.py\", line 408, in train\n    [\"data\", \"label\"], [avg_cost, acc_top1, acc_top5], exe)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "accuracy_0.tmp_0"
    }
    outputs {
      parameter: "Out"
      arguments: "fetch"
    }
    type: "fetch"
    attrs {
      name: "col"
      type: INT
      i: 1
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/io.py\", line 854, in append_fetch_ops\n    attrs={\'col\': i})\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/io.py\", line 973, in save_inference_model\n    append_fetch_ops(main_program, fetch_var_names)\n"
      strings: "  File \"train_resnet.py\", line 408, in train\n    [\"data\", \"label\"], [avg_cost, acc_top1, acc_top5], exe)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
  }
  ops {
    inputs {
      parameter: "X"
      arguments: "accuracy_1.tmp_0"
    }
    outputs {
      parameter: "Out"
      arguments: "fetch"
    }
    type: "fetch"
    attrs {
      name: "col"
      type: INT
      i: 2
    }
    attrs {
      name: "op_role"
      type: INT
      i: 0
    }
    attrs {
      name: "op_role_var"
      type: STRINGS
    }
    attrs {
      name: "op_callstack"
      type: STRINGS
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/framework.py\", line 1306, in append_op\n    attrs=kwargs.get(\"attrs\", None))\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/io.py\", line 854, in append_fetch_ops\n    attrs={\'col\': i})\n"
      strings: "  File \"/home/kbinias/dev/paddle/build/python/paddle/fluid/io.py\", line 973, in save_inference_model\n    append_fetch_ops(main_program, fetch_var_names)\n"
      strings: "  File \"train_resnet.py\", line 408, in train\n    [\"data\", \"label\"], [avg_cost, acc_top1, acc_top5], exe)\n"
      strings: "  File \"train_resnet.py\", line 440, in <module>\n    train(model_map[args.model], args)\n"
    }
    attrs {
      name: "op_namescope"
      type: STRING
      s: "/"
    }
  }
}
